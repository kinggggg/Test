package com.zeek.concurrent.shengsiyuan.concurrent8.concurrency3;

/**
 * 当使用synchronized修饰类的静态方法时,
 * JVM使用了 ACC_STATIC 和 ACC_SYNCHRONIZED 2个访问标志区分一个方法是否为同步方法
 *
 * JVM中的同步是基于进入与退出监视器对象(又称之为管程对象)(Monitor)来实现的, 每个对象实例都会有一个Monitor对象,
 * Monitor对象会和Java对象一同创建并销毁. Monitor对象是由C++来实现的.
 *
 * 当多个线程同时访问一段同步代码时, 这些线程会被放到一个EntryList集合中, 处于阻塞状态的线程都会被放到该列表中.
 * 接下来, 当线程获取到对象的Monitor时, Monitor是依赖于底层操作系统的mutex lock来实现互斥的, 线程获取mutex成功, 则会持有该mutex, 这时其他
 * 线程就无法再获取到该mutex.
 *
 * 如果线程调用了wait方法, 那么该线程就会释放掉所有的mutex, 并且该线程会进入到WaitSet集合(等待集合)中, 等待一下次被其他线程
 * 调用notify/notifyAll唤醒(按照视频中所表达的意思, 此时线程会进入到EntryList中). 如果当前线程顺利执行完毕方法, 那么它也会释放掉所持有的mutex.
 *
 * 总结一下: 同步锁在这种实现方式当中, 因为Monitor是依赖于底层操作系统实现, 这样就存在用户态与内核态之间的切换, 所以会增加系统性能开销.
 *
 * 通过对象互斥锁的概念来保证共享数据操作的完整性. 每个对象都对应于一个可称为"互斥锁"的标记, 这个标记用于保证在任何时刻, 只能有一个线程访问该对象
 *
 * 那些处于EntryList与WaitSet中的线程均处于阻塞状态, 阻塞操作是由操作系统来完成的, 在Linux下是通过pthread_mutex_lock函数来实现的.
 * 线程被阻塞后便会进入到内核调度状态, 这会导致系统在用户态和内核态之间来回切换, 严重影响锁的性能
 *
 * 解决上述问题的办法便是自旋. 其原理是: 当发生对Monitor的争用时, 若Owner能够在很短的时间内释放掉锁, 则那些正在争用的线程就可以稍微等待一下(即所谓的自旋, Spin),
 * 在Owner线程释放锁之后, 争用线程可能会立刻获取到锁, 从而避免了系统阻塞. 不过, 当Owner运行的时间超过了临界值后, 争用线程自旋一段时间后依然无法获取到锁,
 * 这时争用线程则停止自旋而进入到阻塞状态. 所以总体的思想: 先自旋, 不成功再进行阻塞, 尽量降低阻塞的可能性, 这对那些执行时间很短的代码块来说有极大的性能提升.
 * 显然, 自旋在多处理器(多核心)上才有意义
 *
 * 互斥锁的属性:
 * 1. PTHREAD_MUTEX_TIMED_NP: 这是缺省值, 也就是普通锁. 当一个线程加锁以后, 其余请求锁的线程将会形成一个等待队列, 并且在解锁后按照优先级获取到锁. 这种策略可以确保资源分配的公平性
 * 2. PTHREAD_MUTEX_RECURSIVE_NP: 嵌套锁(也就是 可重入锁). 允许同一个线程对同一个锁成功获取多次, 并通过unlock解锁(获取了几次锁, 就需要调用同样次数的unlock方法). 如果是不同线程的请求, 则在加锁线程解锁时重新进行竞争
 * 3. PTHREAD_MUTEX_ERRORCHECK_NP: 检错锁. 如果同一个线程请求同一个锁，则返回EDEADLK, 否则与 PTHREAD_MUTEX_TIMED_NP 类型动作相同, 这样就保证了当不允许多次加锁时不会出现最简单清下的死锁(即, 这样就保证了当允许多次加锁时会出现最简单清下的死锁)
 * 4. PTHREAD_MUTEX_ADAPTIVE_NP: 适应锁. 动作最简单的锁类型, 仅仅等待解锁后重新竞争
 *
 *
 * ============================
 * 在JDK1.5之前，我们若想实现线程同步，只能通过synchronized关键字这一种方式来达成；底层，Java也是通过synchronized关键字来做到数据的原子性维护的；
 * synchronized关键字是JVM实现的一种内置锁（并且是一种重量级锁，针对重量级锁下文会有解释），从底层角度来说，这种锁的获取与释放都是由JVM帮助我们隐式来实现的
 *
 * 从JDK1.5开始，并发包引入了Lock锁，Lock同步锁是基于Java来实现的，因此锁的获取与释放都是通过Java代码来实现与控制的；然而，synchronized
 * 是基于底层操作系统的Mutex Lock来实现的，每次对锁的获取与释放动作都会带来用户态与内核态之间的切换，这种切换会极大地增加系统的负担；在并发量
 * 较高时，也就是说锁的竞争比较激烈时，synchronized锁在性能上的表现就非常差
 *
 * 从JDK1.6开始，synchronized锁的实现发生了很大的变化；JVM引入了相应的优化手段来提升synchronized锁的性能，这种提升涉及到偏向锁、轻量级锁及重量级锁，
 * 从而减少锁的竞争所带来的用户态与内核态之间的切换；这种锁的优化实际上是通过Java对象头中的一些标志位来去实现的；对于锁的访问与改变，实际上都与Java对象头息息相关。
 *
 * 从JDK1.6开始，对象实例在堆当中被划分为三个组成部分：对象头、实例数据与对齐填充
 *
 * 对象头主要也是由3块内容来构成（第2点和第3点需要复习JVM课程，且在这里不相关）：
 * 1. Mark Word
 * 2. 指向类的指针
 * 3. 数组长度
 *
 * 其中Mark Word（它记录了对象、锁及垃圾回收相关的信息，在64位的JVM中，其长度也是64bit）的位信息包括了如下组成部分：
 *
 * 1. 无锁标记
 * 2. 偏向锁标记
 * 3. 轻量级锁标记
 * 4. 重量级锁标记
 * 5. GC标记
 *
 * 对于synchronized锁来说，锁的升级主要都是通过Mark Word中的锁标志位与是否是偏向锁标志位来达成的；synchronized关键字所对应的锁都是先从偏向锁
 * 开始，随着锁竞争的不断升级，逐步演化至轻量级锁，最后则变成了重量级锁
 *
 * 对于锁的演化来说，它会经历如下阶段：
 *
 * 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁
 *
 * 偏向锁：
 * 针对一个线程来说，它的主要作用就是优化同一个线程多次获取一个锁的情况；如果一个synchronized方法被一个线程访问，那么这个方法所在的对象就会在其
 * Mark Word中将偏向锁进行标记，同时还会有一个字段来存储该线程的ID；当这个线程再次访问一个synchronized方法时，它会检查这个对象的Mark Word的
 * 偏向锁标记是否指向了其线程ID，如果是的话，那么该线程就无需再去进入管程（Monitor）了，而是直接进入到该方法体中
 *
 * 如果是另外一个线程访问这个synchronized方法，那么实际情况会如何呢？
 * 偏向锁会被取消掉。
 *
 * 轻量级锁：
 * 若第一个线程已经获取到了当前对象的锁，这时第二个线程又开始尝试争抢该对象的锁，由于该对象的锁已经被第一个线程获取到，因此它是偏向锁，而第二个线程
 * 在争抢时，会发现该对象头中的Mark Word已经是偏向锁，但里面存储的线程ID并不是自己（是第一个线程），那么它会进行CAS（Compare and Swap），从而
 * 获取到锁，这里面存在两种情况：
 * 1. 获取锁成功：那么它会直接将Mark Word中的线程ID由第一个线程变成自己（偏向锁标记位保持不变），这样改对象依然会保持偏向锁的状态
 * 2. 获取锁失败：则表示这时可能有多个线程同时在尝试争抢该对象的锁（从第二个线程的角度是可以判断出来的），那么这时偏向锁会进行升级，升级为轻量级锁
 *  （适合2个线程的情况不适合2个以上线程的情况。这里视频中的解释我感觉不是很好。
 *    来自 https://tech.meituan.com/2018/11/15/java-lock.html 的解释：
 *        "若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。"）
 *
 * 自旋锁：
 * 若自旋失败（依然无法获取到锁），那么锁就会转化为重量级锁，在这种情况下，无法获取到锁的线程都会进入到Monitor（即内核态）
 * 自旋最大的一个特点就是避免了线程从用户态进入到内核态
 *
 * 重量级锁：
 * 线程最终从用户态进入到了内核态
 *
 *
 *
 * @ClassName MyTest3
 * @Description
 * @Author liweibo
 * @Date 2022/1/23 11:53 下午
 * @Version v1.0
 **/
public class MyTest3 {

    public static synchronized void method() {
        System.out.println("hello world");
    }
}
